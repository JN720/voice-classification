{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd2d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio as ta\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ta.set_audio_backend('soundfile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a61adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "melify = ta.transforms.MelSpectrogram(n_mels = 64)\n",
    "\n",
    "SEQSIZE = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f6a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSound(index):\n",
    "    if index < 3682:\n",
    "        audio, _ = ta.load('VoxCeleb_gender/males/' + str(index) + '.flac')\n",
    "    else:\n",
    "        index -= 3682\n",
    "        audio, _ = ta.load('VoxCeleb_gender/females/' + str(index) + '.flac')\n",
    "    audio = melify(audio)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ec0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batching(size, isTrain):\n",
    "    xb = torch.zeros(size, 2, 64, SEQSIZE)\n",
    "    yb = torch.zeros(size, 1, dtype = torch.float32)\n",
    "    bindices = []\n",
    "    if isTrain:\n",
    "        for i in range(size):\n",
    "            bindices.append(xtr[np.random.randint(0, 4795)][0])\n",
    "    else:\n",
    "        for i in range(size):\n",
    "            bindices.append(xte[np.random.randint(0, 1199)][0])\n",
    "    for i in range(len(bindices)):\n",
    "        sound = loadSound(int(bindices[i]))\n",
    "        start = np.random.randint(0, sound.shape[-1] - SEQSIZE)\n",
    "        xb[i] = sound[:, :, start:start + SEQSIZE]\n",
    "        yb[i] = y[int(bindices[i])]\n",
    "    return xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec69f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24182 max\n",
    "#953 min\n",
    "#4795 tr 1199 te\n",
    "y = torch.cat((torch.ones(3682, 1, dtype = torch.float32), torch.zeros(2312, 1, dtype = torch.float32)), dim = 0)\n",
    "x = torch.tensor(np.arange(5994)).unsqueeze(-1).long().numpy()\n",
    "xtr, xte, ytr, yte = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e1c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(2, 8, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6144, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "model = Model()\n",
    "maxacc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33685195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 90\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0007\n",
    "TEST_FREQ = 5\n",
    "TEST_SIZE = 200\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    xbatch, ybatch = batching(BATCH_SIZE, True)\n",
    "    preds = model(xbatch)\n",
    "    loss = criterion(preds, ybatch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % TEST_FREQ == TEST_FREQ - 1:\n",
    "        acc = 0\n",
    "        with torch.no_grad():\n",
    "            xbatch, ybatch = batching(TEST_SIZE, False)\n",
    "            preds = torch.round(model(xbatch))\n",
    "            ybatch = ybatch.squeeze()\n",
    "            for i in range(TEST_SIZE):\n",
    "                if preds[i] == ybatch[i]:\n",
    "                    acc += 1\n",
    "        print('Epoch: {} Loss: {} Acc: {}%'.format(epoch + 1, loss.item(), acc * 100.0 / TEST_SIZE))\n",
    "        if acc > maxacc:\n",
    "            torch.save(model.state_dict(), 'MVCBaseline.pt')\n",
    "            maxacc = acc\n",
    "            print('New Record')\n",
    "acc = 0\n",
    "model.load_state_dict(torch.load('MVCBaseline.pt'))\n",
    "with torch.no_grad():\n",
    "    xbatch, ybatch = batching(1000, False)\n",
    "    preds = torch.round(model(xbatch))\n",
    "    ybatch = ybatch.squeeze()\n",
    "    for i in range(1000):\n",
    "        if preds[i] == ybatch[i]:\n",
    "            acc += 1\n",
    "print('Final Val: {}%'.format(acc * 100.0 / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b49f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MVC89-8.pt') #89.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a202dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 441600])\n",
      "tensor([[0.4717]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 0 = feminine 1 = masculine\n",
    "audio, _ = ta.load('insert filepath here')\n",
    "print(audio.shape)\n",
    "start = 100\n",
    "audio = melify(audio)\n",
    "MVC = Model()\n",
    "MVC.load_state_dict(torch.load('MVC89-8.pt'))\n",
    "audio = audio[:, :, start:start + SEQSIZE]\n",
    "print(model(audio.unsqueeze(0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
